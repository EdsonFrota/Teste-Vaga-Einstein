01. 
Um dataset desbalanceado pode ser um grande desafio quando estamos trabalhando com modelos de classificação. Imagine que você está tentando prever fraudes em transações financeiras, mas, no seu conjunto de dados, apenas 1% dos registros são fraudes e os outros 99% são transações normais. Esse desequilíbrio pode fazer com que o modelo fique "viciado" em prever sempre a classe majoritária, ou seja, ele pode simplesmente classificar tudo como "não fraude" e ainda assim ter uma alta acurácia. Só que, nesse caso, o modelo não está ajudando em nada, porque o que a gente realmente quer é identificar as fraudes, que são justamente a classe minoritária.

Esse problema acontece porque o modelo, durante o treinamento, acaba priorizando a classe que aparece mais vezes, já que o objetivo é minimizar o erro geral. Como resultado, ele pode ignorar completamente os padrões da classe minoritária, levando a uma baixa taxa de detecção (recall) para essa classe. Além disso, métricas como a acurácia podem enganar, porque elas não refletem o desempenho real do modelo nas classes menos frequentes.

Para resolver isso, existem algumas estratégias que podem ser aplicadas. Uma delas é tentar coletar mais dados da classe minoritária, mas nem sempre isso é possível. Outra abordagem é usar técnicas de reamostragem, como o oversampling, que aumenta a quantidade de exemplos da classe minoritária, ou o undersampling, que reduz a quantidade de exemplos da classe majoritária. Uma técnica bastante usada é o SMOTE, que cria novos exemplos sintéticos da classe minoritária, ajudando a equilibrar o dataset.

Outra solução é ajustar os pesos das classes durante o treinamento do modelo. Isso faz com que o modelo dê mais importância aos erros cometidos na classe minoritária, penalizando mais quando ele erra nessa classe. Além disso, é importante usar métricas de avaliação mais adequadas, como precisão, recall e F1-Score, que ajudam a entender melhor o desempenho do modelo em relação às classes desbalanceadas.

Por fim, alguns algoritmos, como Random Forest ou XGBoost, lidam melhor com datasets desbalanceados, e técnicas como ensemble learning também podem ser úteis. O importante é escolher a abordagem que faz mais sentido para o problema que você está tentando resolver.

-------------------------------------------------------------------------------------------------------------------------------------------------
02. 

import pandas as pd

# Supondo que o arquivo se chame 'vendas.csv'
df = pd.read_csv('vendas.csv')

# Passo 2: Calcular o faturamento total por produto
df['faturamento'] = df['quantidade'] * df['preco_unitario']

# Agrupando por 'produto' e somando o faturamento
faturamento_por_produto = df.groupby('produto')['faturamento'].sum().reset_index()

# Passo 3: Produto com maior e menor faturamento
produto_maior_faturamento = faturamento_por_produto.loc[faturamento_por_produto['faturamento'].idxmax()]
produto_menor_faturamento = faturamento_por_produto.loc[faturamento_por_produto['faturamento'].idxmin()]

# Exibir os resultados
print("Faturamento por produto:")
print(faturamento_por_produto)
print("\nProduto com maior faturamento:")
print(produto_maior_faturamento)
print("\nProduto com menor faturamento:")
print(produto_menor_faturamento)
-------------------------------------------------------------------------------------------------------------------------------------------------
03.
Criar a API:

    Endpoint GET /saudacao que recebe um parâmetro nome e retorna uma mensagem de saudação personalizada.
from flask import Flask, request, jsonify

# Inicializa o Flask
app = Flask(__name__)

# Endpoint 1: GET /saudacao
@app.route('/saudacao', methods=['GET'])
def saudacao():
    # Obtém o parâmetro 'nome' da query string
    nome = request.args.get('nome')
    
    if nome:
        mensagem = f"Olá, {nome}! Tudo bem?"
    else:
        mensagem = "Olá! Qual é o seu nome?"
    
    return jsonify({"mensagem": mensagem})

# Endpoint 2: POST /soma
@app.route('/soma', methods=['POST'])
def soma():
    
    dados = request.get_json()
    
    # Verifica se os campos 'numero1' e 'numero2' estão presentes no JSON
    if 'numero1' in dados and 'numero2' in dados:
        numero1 = dados['numero1']
        numero2 = dados['numero2']
        resultado = numero1 + numero2
        return jsonify({"resultado": resultado})
    else:
        
        return jsonify({"erro": "Por favor, forneça 'numero1' e 'numero2' no JSON."}), 400

if __name__ == '__main__':
    app.run(debug=True)

-------------------------------------------------------------------------------------------------------------------------------------------------
04
import asyncio
import time

# Função assíncrona que simula uma chamada de rede
async def simular_chamada_rede(segundos):
    print(f"Iniciando chamada de rede que levará {segundos} segundos...")
    await asyncio.sleep(segundos)  # Simula uma operação que leva tempo
    print(f"Chamada de rede de {segundos} segundos concluída!")

# Função assíncrona principal que executa as três chamadas
async def main():
    # Inicia o cronômetro
    inicio = time.time()
    
    # Executa as três chamadas de rede de forma assíncrona
    await asyncio.gather(
        simular_chamada_rede(2),  # Chamada 1: 2 segundos
        simular_chamada_rede(3),  # Chamada 2: 3 segundos
        simular_chamada_rede(1)   # Chamada 3: 1 segundo
    )
    
    # Calcula o tempo total de execução
    tempo_total = time.time() - inicio
    print(f"Tempo total de execução: {tempo_total:.2f} segundos")

# Roda a função assíncrona principal
if __name__ == '__main__':
    asyncio.run(main())
-------------------------------------------------------------------------------------------------------------------------------------------------
05
1. Containerização da API com Docker

    Criar um Dockerfile definindo a imagem da API Flask.
    Executar docker build -t minha-api . para construir a imagem.
    Testaria localmente com docker run -p 5000:5000 minha-api.

2. Publicação no Amazon Elastic Container Registry (ECR)

    Criar um repositório no ECR (aws ecr create-repository --repository-name minha-api).
    Fazer login no ECR (aws ecr get-login-password | docker login --username AWS --password-stdin <ecr-url>).
    Subir a imagem para o ECR (docker push <ecr-url>/minha-api:latest).

3. Deploy na AWS

Utilizando EC2:

    Criaria uma instância EC2 e instalaria Docker (sudo yum install -y docker && sudo service docker start).
    Faria 'pull' da imagem do ECR e rodaria o container (docker run -d -p 80:5000 <ecr-url>/minha-api).
    Configuraria um security group para liberar a porta 80.

4. Configuração de DNS e HTTPS (Opcional)

    Criaria um domínio no Route 53 e configuraria um registro apontando para o Load Balancer ou IP da EC2.
    Configuraria um certificado SSL via AWS Certificate Manager para HTTPS.
-------------------------------------------------------------------------------------------------------------------------------------------------
06
    Criar o Dockerfile: Especifica as instruções para construir a imagem do contêiner.
# Usa uma imagem base do Python
FROM python:3.9-slim

# Define o diretório de trabalho dentro do contêiner
WORKDIR /app

# Copia o arquivo de dependências para o contêiner
COPY requirements.txt .

# Instala as dependências
RUN pip install --no-cache-dir -r requirements.txt

# Copia o código da aplicação para o contêiner
COPY . .

# Expõe a porta 5000 (porta padrão do Flask)
EXPOSE 5000


# Comando para rodar a aplicação
CMD ["python", "app.py"]
-------------------------------------------------------------------------------------------------------------------------------------------------
07
A senha '1234' está fixada diretamente no código, o que é uma má prática de segurança. Senhas devem ser armazenadas de forma segura, como em um banco de dados com hash.
Os dados de entrada (username e password) não são validados, o que pode levar a ataques como injeção de código ou manipulação de dados.
O modo de depuração (debug=True) nunca deve ser usado em produção, pois ele expõe informações sensíveis e pode permitir a execução de código arbitrário.
Não há mecanismos para limitar tentativas de login, o que facilita ataques de força bruta.
O código não força o uso de HTTPS, o que significa que as credenciais são transmitidas em texto claro, vulneráveis a interceptação.
As mensagens de "Acesso concedido" e "Acesso negado" são genéricas e podem fornecer dicas para um hacker.

Código Corrigido:
from flask import Flask, request, jsonify
from werkzeug.security import generate_password_hash, check_password_hash
from flask_limiter import Limiter
from flask_limiter.util import get_remote_address
import os

app = Flask(__name__)

# Configuração do Flask-Limiter para prevenir ataques de força bruta
limiter = Limiter(
    get_remote_address,
    app=app,
    default_limits=["5 per minute"]  # Limita a 5 tentativas de login por minuto
)

SENHA_ADMIN_HASH = generate_password_hash('1234')  # Gera um hash da senha

@app.route('/login', methods=['POST'])
@limiter.limit("5 per minute")  # Aplica o limite de taxa à rota /login
def login():

    if not request.form.get('username') or not request.form.get('password'):
        return jsonify({"erro": "Usuário e senha são obrigatórios"}), 400

    username = request.form['username']
    password = request.form['password']


    if username == 'admin' and check_password_hash(SENHA_ADMIN_HASH, password):
        return jsonify({"mensagem": "Acesso concedido"}), 200
    else:
        return jsonify({"mensagem": "Credenciais inválidas"}), 401

if __name__ == '__main__':
    # Desativa o modo de depuração em produção
    debug_mode = os.getenv('FLASK_DEBUG', 'False').lower() == 'true'
    app.run(debug=debug_mode)
-------------------------------------------------------------------------------------------------------------------------------------------------
07
Teve uma situação em que precisei resolver um problema crítico sob pressão. O sistema estava extremamente lento ao processar determinadas solicitações, impactando diretamente o tempo de resposta e a eficiência do atendimento. Isso gerou uma grande urgência, pois os usuários dependiam dessa funcionalidade para tomar decisões rapidamente.

Diante disso, mantive a calma e foquei em entender a causa raiz do problema. Analisei logs, revisei queries no banco e identifiquei que uma consulta específica estava consumindo muitos recursos devido ao grande volume de dados processados. Para lidar com a pressão, adotei uma abordagem estruturada, dividindo o problema em partes menores e testando soluções de forma iterativa.

Após otimizar a consulta SQL e ajustar índices no banco, conseguimos reduzir significativamente o tempo de resposta. O resultado foi um sistema mais ágil e eficiente, melhorando a experiência dos usuários. Além disso, documentei as melhorias para evitar que o problema ocorresse novamente no futuro.